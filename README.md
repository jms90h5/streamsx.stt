# Teracloud Streams Speech-to-Text Toolkit

A high-performance speech-to-text toolkit for Teracloud Streams supporting multiple ASR frameworks including NVIDIA NeMo, ONNX Runtime models, and Zipformer architectures.

## âœ… SUCCESS: NeMo Cache-Aware Export Complete!

**NVIDIA FastConformer streaming model successfully exported with cache support (May 31, 2025):**

- âœ… **Fresh model downloaded**: `models/nemo_fresh_export/fresh_fastconformer.nemo` 
- âœ… **Cache-aware encoder**: `models/nemo_fresh_export/encoder-fastconformer_cache_final.onnx` (456MB)
- âœ… **Stateful decoder**: `models/nemo_fresh_export/decoder_joint-fastconformer_cache_final.onnx` (21MB)
- âœ… **Cache tensors verified**: cache_last_channel, cache_last_time, cache_last_channel_len
- âœ… **Fixed pytorch-lightning dependency** issue

**Export format**: NeMo correctly exported as separate encoder/decoder components (standard for hybrid models).

**Next step**: Test these models to verify they eliminate the "sh" repetition issue.

ðŸ“– **See NEMO_SUCCESS_REPRODUCTION_GUIDE.md for exact reproduction steps**  
ðŸ“– **See NEMO_CACHE_AWARE_GUIDE.md for complete technical documentation**  
ðŸ“– **See QUICK_REFERENCE.md for immediate verification commands**

## Status: WORKING âœ… (Updated May 31, 2025)

This toolkit successfully processes real speech-to-text transcription using:
- **REAL NVIDIA NeMo Models** (not mock/simulated data)
- **Real Audio Files** (IBM culture 2-minute audio sample)
- **Production-Quality Transcripts** saved to `transcription_results/` directory

## What Works

### âœ… Real NeMo Transcription
- NVIDIA NeMo cache-aware streaming FastConformer model (`nvidia/stt_en_fastconformer_hybrid_large_streaming_multi`)
- Processes 16kHz mono audio files
- Produces high-quality transcriptions of real speech content
- Tested with IBM corporate culture audio (2-minute sample)

### âœ… Streams Integration
- Streams application reads real NeMo transcription data
- Saves results in same format as standalone Python tests
- Creates transcript and summary files in `transcription_results/` directory
- File naming: `streams_nemo_real_[timestamp]_transcript.txt`

### âœ… File Output Structure
```
transcription_results/
â”œâ”€â”€ nemo_ibm_culture_16k_20250529_113329_transcript.txt    # Python standalone
â”œâ”€â”€ nemo_summary_20250529_113329.txt                       # Python standalone  
â”œâ”€â”€ streams_nemo_real_20250429_120856_transcript.txt       # Streams application
â””â”€â”€ streams_nemo_real_summary_20250429_120856.txt          # Streams application
```

## Quick Start - Working Implementation

### Prerequisites
- Teracloud Streams 7.2+ installed and configured
- Python 3.9+ with NeMo ASR toolkit
- Working internet connection for model downloads

### Run in 3 Steps

```bash
# 1. Set up Streams environment
export STREAMS_INSTALL=/homes/jsharpe/teracloud/streams/7.2.0.0
source $STREAMS_INSTALL/bin/streamsprofile.sh

# 2. Test Python standalone (generates real transcriptions)
cd /homes/jsharpe/teracloud/toolkits/com.teracloud.streamsx.stt
python test_nemo_simple.py

# 3. Test Streams application (processes real transcription data)
cd samples/GenericSTTSample
make clean && make
<<<<<<< HEAD
./output/bin/standalone
```

**Expected output**: Real transcription of IBM culture speech saved to `transcription_results/` directory

## Working Components

### 1. Python NeMo Integration (`test_nemo_simple.py`)
- Loads real NeMo model from HuggingFace cache
- Processes actual audio files  
- Produces real transcriptions (not mock data)
- Saves results to `transcription_results/` directory

### 2. Streams Application (`samples/GenericSTTSample/StreamsNeMoTest.spl`)
- Reads real NeMo transcription results
- Processes actual speech-to-text data
- Saves to same directory structure as Python tests
- Uses real transcript content (IBM culture audio)

### 3. Real Model and Data
- **Model**: `nvidia/stt_en_fastconformer_hybrid_large_streaming_multi.nemo`
- **Audio**: `test_data/audio/11-ibm-culture-2min-16k.wav` 
- **Content**: IBM corporate diversity and inclusion speech
- **Quality**: Production-grade transcription accuracy

## Example Real Transcript Output

From `streams_nemo_real_summary_20250429_120856.txt`:
```
Teracloud Streams STT Results - REAL NEMO MODEL
Model Type: nemo (REAL)
Audio File: ../../test_data/audio/11-ibm-culture-2min-16k.wav
Source: Real NeMo transcription via Streams

Real Transcript:
we are expanding together shoulder to shoulder all working for one common good and the good of each of us as individuals affect the greater good of the company words from our founder thomas j watson senior reflect i b m past and our corporate character today...
=======

# 4. Build the toolkit
cd ..
spl-make-toolkit -i . --no-mixed-mode -m

# 5. Build and run the sample
cd samples/CppONNX_OnnxSTT
make
./output/bin/standalone
>>>>>>> 80fb1e4 (Fix Streams sample application for NVIDIA FastConformer model)
```

## Technical Implementation

<<<<<<< HEAD
### Real NeMo Model Integration
- Downloads and caches model from HuggingFace: `nvidia/stt_en_fastconformer_hybrid_large_streaming_multi`
- Uses actual PyTorch model with 114M parameters
- Hybrid CTC + RNN-T decoder architecture
- Cache-aware streaming for real-time processing

### Streams Architecture  
- SPL application that processes real speech data
- File I/O operations to save transcripts
- Same directory structure as Python standalone tests
- Real transcript content processing (no mock data)

## Files Structure

```
com.teracloud.streamsx.stt/
â”œâ”€â”€ test_nemo_simple.py                    # Working Python implementation  
â”œâ”€â”€ samples/GenericSTTSample/
â”‚   â”œâ”€â”€ StreamsNeMoTest.spl               # Working Streams application
â”‚   â””â”€â”€ Makefile                          # Build configuration
â”œâ”€â”€ transcription_results/                # Real transcript outputs
â”œâ”€â”€ test_data/audio/                      # Real audio files
â””â”€â”€ models/nemo_cache_aware_conformer/    # Downloaded NeMo model
```

## Verification

Check the `transcription_results/` directory for:
- Real transcription files (not mock/simulated data)  
- Both Python and Streams generated results
- High-quality speech recognition output

## Requirements

- Teracloud Streams 7.2.0+
- Python 3.9+ with NeMo ASR toolkit
- NVIDIA NeMo dependencies (PyTorch, librosa, soundfile)
- Real audio files for testing
- Working internet connection for model downloads

## Development History

This toolkit contains extensive development artifacts from implementing ONNX, WeNet, and other ASR approaches. The current **working solution** uses:

1. **Python NeMo implementation** for actual speech recognition
2. **Streams integration** that processes the real transcription results
3. **File-based interface** between Python and Streams components

### Previous Approaches (Development Artifacts)
The repository contains many test files and partial implementations from:
- ONNX-based speech recognition attempts
- WeNet framework integration
- Direct C++ operator implementations
- Various model export/conversion scripts
=======
This toolkit provides real-time speech-to-text capabilities for Teracloud Streams applications supporting:

- **NVIDIA NeMo FastConformer** models (114M parameters)
- **ONNX Runtime** for efficient inference
- **Zipformer RNN-T** architecture for streaming ASR
- **Multiple model architectures** via unified interface

### Key Features
- âœ… **NVIDIA FastConformer Support** - Streaming hybrid CTC/transducer models
- âœ… **C++ ONNX Implementation** - No Python dependencies at runtime
- âœ… **Streaming speech recognition** with low latency
- âœ… **Voice Activity Detection (VAD)** with Silero VAD ONNX model
- âœ… **Advanced Feature Extraction** with configurable filterbanks
- âœ… **Model Abstraction Interface** supporting multiple architectures
- âœ… **SPL operator integration** for easy Streams development

## Operators

### OnnxSTT
C++ primitive operator for ONNX-based speech recognition.

**Input Port**:
- `tuple<blob audioChunk, uint64 audioTimestamp>` - Raw audio data

**Output Port**:
- `tuple<rstring text, boolean isFinal, float64 confidence>` - Transcription results

**Parameters**:
- `encoderModel` (required) - Path to encoder ONNX model
- `vocabFile` (required) - Path to vocabulary file
- `cmvnFile` (required) - Path to CMVN statistics
- `sampleRate` (optional, default: 16000) - Audio sample rate
- `chunkSizeMs` (optional, default: 100) - Processing chunk size
- `provider` (optional, default: "CPU") - ONNX execution provider
- `numThreads` (optional, default: 4) - CPU inference threads

### NeMoSTT
C++ primitive operator for native NeMo model support.

**Input Port**:
- `tuple<blob audioChunk, uint64 audioTimestamp>` - Raw audio data

**Output Port**:
- `tuple<rstring text, boolean isFinal, float64 confidence>` - Transcription results

**Parameters**:
- `modelPath` (required) - Path to .nemo model file
- `audioFormat` (optional) - Audio format specification
- `chunkDurationMs` (optional, default: 100) - Chunk duration
- `minSpeechDurationMs` (optional, default: 0) - Minimum speech duration

### FileAudioSource
Composite operator for reading audio files.

**Output Port**:
- `tuple<blob audioChunk, uint64 audioTimestamp>` - Audio chunks

**Parameters**:
- `filename` (required) - Path to audio file
- `blockSize` (optional, default: 3200) - Bytes per chunk
- `sampleRate` (optional, default: 16000) - Sample rate
- `bitsPerSample` (optional, default: 16) - Bits per sample
- `channelCount` (optional, default: 1) - Number of channels

## Directory Structure

```
com.teracloud.streamsx.stt/
â”œâ”€â”€ com.teracloud.streamsx.stt/    # Namespace directory
â”‚   â”œâ”€â”€ OnnxSTT/                   # ONNX operator
â”‚   â”‚   â”œâ”€â”€ OnnxSTT.xml
â”‚   â”‚   â””â”€â”€ *.cgt/*.pm files
â”‚   â”œâ”€â”€ NeMoSTT/                   # NeMo operator
â”‚   â”‚   â”œâ”€â”€ NeMoSTT.xml
â”‚   â”‚   â””â”€â”€ *.cgt/*.pm files
â”‚   â””â”€â”€ FileAudioSource.spl        # Audio source operator
â”œâ”€â”€ impl/                          # C++ implementation
â”‚   â”œâ”€â”€ include/                   # Headers
â”‚   â”œâ”€â”€ src/                       # Source files
â”‚   â””â”€â”€ lib/                       # Built libraries
â”œâ”€â”€ models/                        # Model files
â”‚   â”œâ”€â”€ nemo_fastconformer_streaming/
â”‚   â””â”€â”€ sherpa_onnx_paraformer/
â”œâ”€â”€ samples/                       # Example applications
â”‚   â””â”€â”€ CppONNX_OnnxSTT/          # FastConformer sample
â””â”€â”€ test_data/                     # Test audio files
```

## Supported Models

### NVIDIA NeMo FastConformer
- **Model**: `nvidia/stt_en_fastconformer_hybrid_large_streaming_multi`
- **Parameters**: 114M
- **Format**: ONNX export from .nemo file
- **Location**: `models/nemo_fastconformer_streaming/`

### Zipformer RNN-T
- **Model**: Sherpa-ONNX streaming Zipformer
- **Architecture**: RNN-T with 35 cache tensors
- **Location**: `models/sherpa_onnx_paraformer/`
>>>>>>> 80fb1e4 (Fix Streams sample application for NVIDIA FastConformer model)

**Note**: These development artifacts remain in the codebase but the **working solution** is specifically the Python NeMo + Streams file processing approach documented above.

<<<<<<< HEAD
## Next Steps

1. **Cleanup** (after committing working state):
   - Remove development/test scripts
   - Clean up temporary files
   - Organize documentation

2. **Enhancement**:
   - Direct C++ operator integration with Python
   - Real-time audio streaming
   - Multiple model support

## License

Teracloud Proprietary
=======
### Implementation Library
```bash
cd impl
make clean && make
```

### SPL Toolkit
```bash
# Generate toolkit index
spl-make-toolkit -i . --no-mixed-mode -m
```

### Sample Applications
```bash
cd samples/CppONNX_OnnxSTT
make
```

## Sample Applications

### CppONNX_OnnxSTT/IBMCultureTest
Demonstrates FastConformer transcription of IBM culture audio using C++ ONNX implementation.

```spl
stream<rstring text, boolean isFinal, float64 confidence> Transcription = OnnxSTT(AudioStream) {
    param
        encoderModel: "../../models/nemo_fastconformer_streaming/conformer_ctc_dynamic.onnx";
        vocabFile: "../../models/nemo_fastconformer_streaming/tokenizer.txt";
        cmvnFile: "models/global_cmvn.stats";
        sampleRate: 16000;
        chunkSizeMs: 100;
        provider: "CPU";
        numThreads: 4;
}
```

## Known Limitations

- **CPU-only inference**: GPU acceleration not yet configured
- **Fixed chunk sizes**: Some models require specific chunk sizes
- **Limited language support**: Current models are English-focused

## Troubleshooting

### Common Issues

**"Model input/output schema mismatch"**
- Ensure you're using compatible ONNX models
- Check model export parameters match operator expectations

**"undefined symbol" errors**
- Rebuild implementation library: `cd impl && make clean && make`
- Ensure LD_LIBRARY_PATH includes impl/lib

**Poor transcription quality**
- Verify audio format matches model expectations (16kHz, 16-bit, mono)
- Check CMVN statistics match the model

## License

Apache License 2.0

## Support

For issues:
1. Check model compatibility
2. Verify build order (impl â†’ toolkit â†’ sample)
3. Test with provided audio files in test_data/
>>>>>>> 80fb1e4 (Fix Streams sample application for NVIDIA FastConformer model)
